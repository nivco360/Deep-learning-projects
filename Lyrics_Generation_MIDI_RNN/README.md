# Lyrics Generation with MIDI-Conditioned RNN

This project explores the generation of song lyrics using recurrent neural networks (RNNs) conditioned on MIDI-derived musical features. The model aims to incorporate melodic and rhythmic structure into the language modeling process.

---

## üìö Overview

The task is framed as a language modeling problem: given a seed text and musical conditioning (melody and rhythm), the model learns to predict the next word in a sequence. Two model variants were tested:

1. **Melody-only conditioning**
2. **Melody + Rhythm conditioning**

Although the generated lyrics were limited in quality, the project offers insights into how symbolic musical data can influence natural language generation.

---

## üóæÔ∏è Dataset and Preprocessing

- **Text Source**: Lyrics corpus
- **Music Source**: Corresponding MIDI files for each song

### üîÑ Preprocessing Pipeline

- MIDI files were parsed to extract:
  - Melody vector
  - Rhythm vector
- Word-level tokenization
- Word2Vec embedding of lyrics
- Conditioning vectors were synchronized with lyric positions

Code for this step is located in `lyrics_midi_preprocess.py`

---

## üõçÔ∏è Architecture

The model integrates textual and musical input through the following components:

- Word2Vec embedding for lyrics
- Melody and rhythm vectors as parallel inputs
- **Three GRU layers**
- **Three Linear layers** with intermediate activation and normalization:
  - ReLU
  - Dropout
  - LayerNorm
- Softmax output layer (predicts word probability distribution)

---

## üîß Training Details

- **Optimizer**: SGD
- **Loss**: Cross-Entropy
- **Learning Rate**: 0.001
- **Batch Size**: 64
- **Embedding Size**: 300 (Word2Vec)
- **Epochs**: 10

Training was conducted on both model variants using identical hyperparameters.

---

## üìä Results

### üî¢ Training and Validation Loss

Loss curves show good convergence for both models:



- Melody-only and Melody+Rhythm models both reached stable loss after 10 epochs
- Rhythm input did not improve loss but did not hinder learning either

---

## ‚ö†Ô∏è Limitations

- Lyrics generated were **semantically poor** and lacked structure
- Word2Vec did not capture sufficient context for coherence
- Future improvements may include:
  - Transformer-based decoding
  - Attention over musical context
  - Filtering unaligned or noisy sequences


